<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vehicle Detection and Classification Proposal</title>
    <link rel="stylesheet" href="index.css">
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Vehicle Detection and Classification Proposal</h1>
            <h3>Jiya Varma, Madeline Liu Hou, Mengzhu Ou, Nicole Hernandez Canales, Sophia Isabel Marples Rodriguez</h3>
            <a href="https://github.com/mengzhuou/CS4641_CarClassification" class="btn" target="_blank">View on GitHub</a>
        </div>
    </header>

    <main>
        <section id="introduction">
            <h2>Introduction</h2>
            <p>Vehicle detection and classification are crucial for traffic control, management, and surveillance, but manual monitoring of traffic footage is inefficient, considering the volume of vehicles in high-traffic areas. Automated vehicle classification systems can address this problem by using machine learning algorithms to detect and categorize vehicles in real-time.</p><br/>
            <h3>Literature Review</h3>
            <p>
                Automated vehicle classification systems remain difficult to implement, considering issues such as the computational constraints of video processing, the effect of poor weather and environmental conditions, and occlusion [1]. Researchers have focused on improving vehicle detection using machine learning classifiers and deep learning methods, such as CNN-based methods, YOLO, and Vision Transformer (ViT) techniques [1], [2], [3].
            </p><br/>

            <h3>Dataset Description</h3>
            <p>We plan to use the Stanford Cars dataset for training our models. The dataset contains 16,185 images across 196 different classes of cars, with annotations for each class describing the make, model, and year of the car. </p><br/>
            <li><a href="https://www.kaggle.com/datasets/jessicali9530/stanford-cars-dataset" target="_blank">Dataset Link</a></li>
            </ul>
        </section>

        <section id="problem-definition">
            <h2>Problem Definition</h2>
            <p>In our project, we seek to identify and classify cars from an image, and also to detect their license plate. As previously covered, the uses of license plate detection and car classification range from law enforcement to traffic control. Our project seeks to improve upon existing methods.</p>
        </section>
        
        <section id="gantt">
            <h2>Gantt Chart</h2>
            <a href="https://gtvault-my.sharepoint.com/:x:/r/personal/srodriguez67_gatech_edu/_layouts/15/Doc.aspx?sourcedoc=%7B83F8A18E-E3EF-4F5F-86D2-9EF9D988573C%7D&file=GanttChart.xlsx&fromShare=true&action=default&mobileredirect=true" target="_blank">Gantt Chart Link</a>
        </section>

        <section id="methods">
            <h2>Implemented Methods</h2>
            <p>We will resize all images to ensure consistent input dimensions, as neural networks require uniform image sizes for layers like convolution. Data augmentation (e.g., rotation, flipping, noise injection and reduction, cropping) will be applied to generate additional images, increasing the dataset size and preventing overfitting [4]. Pixel normalization will standardize lighting conditions and ensure consistent image scales.</p>
            <p>The Vision Transformer (ViT) requires “patches” from the input image, and thus a patch-creation pre-processing step will be required [5]. We plan to train 2 supervised models, Convolution neural networks (CNN) and Vision transformer (ViT), and one unsupervised model, Gaussian Mixture model (GMM), for car classification.</p>
            <ul>
                <li>CNNs are effective in image classification due to hierarchical feature detection (e.g., edges, wheels, chassis detection) and translation invariance (e.g., different angles/location of car in images) when trained on a strong dataset [Source].</li>
                <li>ViT, which sequentially processes image patches using self-attention, has shown comparable performance to CNNs when trained on large datasets [6].</li>
                <li>GMM will reduce our dataset's class size of car makes/models to fewer clusters of chassis shapes (e.g., sedan, coupe, SUV), creating a more manageable dataset for training.</li>
            </ul>
        </section>

        <section id="methods">
            <h2>Data Cleaning</h2>
            <p>To ensure the quality and consistency of our dataset, we implemented several data cleaning steps across both the training and test datasets:</p>
            <ul>
                <li><strong>Folder Filtering</strong>: Folders containing 30 or fewer images were removed. This threshold was set to maintain a balanced distribution of images per category.</li>
                <li><strong>Image Resizing with Aspect Ratio Preservation</strong>: All images were resized to a consistent target size of 224 x 224 pixels. To avoid distortion, aspect ratios were preserved, and padding was added where necessary. This ensured that all images met the required input dimensions for the neural network without compromising image quality.</li>
                <li><strong>Format Standardization</strong>: All images were converted to the JPEG format to establish consistent compatibility with the neural network and ensure consistency across the dataset.</li>
            </ul>
        </section>


        <section id="results-discussion">
            <h2>Results and Discussion</h2>
        
            <p>The ResNet model implemented here is inspired by Microsoft's 2015 ResNet architecture, leveraging residual blocks to enable deep learning without gradient vanishing or explosion issues. Each residual block in the model comprises two convolutional layers with batch normalization, connected by skip connections. These skip connections help preserve gradients across layers, allowing for more stable and effective training even in deep networks. The model processes input data through an initial convolution, followed by three residual blocks that increase the number of filters to capture complex features. A bottleneck 1x1 convolution aligns the dimensions between residual blocks to keep the feature map size consistent, which is essential for efficient learning without inflating computational costs. The model concludes with a global average pooling layer, flattening, and a dense softmax layer for classification. The use of sparse categorical cross-entropy as the loss function helps simplify label handling, and the Adam optimizer accelerates convergence with minimal hyperparameter adjustments.</p>
            <br>

            <h3>Initial Evaluation (0% Accuracy)</h3>
            <p>The first run, with 196 classes and no data augmentation, yielded 0% test accuracy (initally 1% at epoch 1, but decreased with each epoch) and no meaningful precision, recall, or F1 scores across classes. This was largely due to the high class count, which overwhelmed the model, and the computational burden from the 1x1 bottleneck convolution layer, which introduced inefficiencies. The confusion matrix revealed nearly random predictions, indicating severe underfitting. At this stage, the model lacked the ability to generalize effectively, likely due to insufficient gradient flow and difficulty learning distinctive features for each class.</p>
            <br>

            <h3>Second Evaluation (13% Accuracy, Reduced Classes)</h3>
            <p>Reducing the class count from 196 to 48 improved the model's ability to distinguish between brands, resulting in a 13% accuracy increase. This reduction made the task more manageable, allowing the model to start learning specific brand features, though still at a limited level. Precision and recall scores showed modest improvement, particularly for brands like Aston Martin, Ferrari, and Chevrolet. The confusion matrix demonstrated an increase in correctly predicted classes but still displayed significant misclassifications, suggesting further optimization was needed.</p>
            <br>

            <h3>Third Evaluation (17% Accuracy, Added Data Augmentation)</h3>
            <p>Adding data augmentation layers led to a 17% test accuracy, as augmentation introduced variability in the training set, allowing the model to generalize better across different lighting, contrast, and orientation conditions. Brands like Audi, BMW, Chrysler, and Ferrari saw further improvement in precision, recall, and F1 scores, indicating that the model was increasingly capable of recognizing brand-specific features. The confusion matrix showed increased clustering along the diagonal, especially for brands with a substantial number of samples, though performance on less-represented brands remained low.</p>
            <br>

            <h3>Fourth Evaluation (32% Accuracy, 30 Epochs)</h3>
            <p>The model reached 32% accuracy after training for 30 epochs, allowing it to better internalize features across brands. This run saw notable improvements in both precision and recall for brands like Acura, Audi, BMW, Ferrari, and HUMMER. The longer training time allowed the model to recognize distinctive patterns, but brands with limited data still had poor performance, as reflected in the confusion matrix. This indicates a need for techniques to address class imbalance, such as weighted loss functions, to further improve generalization.</p>
            <br>

            <h3>Fifth Evaluation (38% Accuracy, 50 Epochs, Overfitting Observed)</h3>
            <p>With 50 epochs, the model achieved a 38% test accuracy and an F1 score of 0.37. However, training accuracy reached 70%, suggesting overfitting as the validation accuracy stagnated at 36%. This was confirmed in the confusion matrix, where frequently seen brands showed strong performance while rarer brands remained problematic. The model learned specific details rather than general patterns, which compromised its ability to generalize. Regularization methods, such as dropout or weight decay, may help prevent this overfitting in future runs.</p>
            <br>

            <h3>Sixth Evaluation (24% Accuracy, Extra Activation Layer)</h3>
            <p>Adding a separate activation layer on top of batch normalization within the residual blocks reduced test accuracy to 24% and F1 score to 0.2, indicating degraded model performance. The addition of an extra activation layer disrupted the learning dynamics within residual blocks, as seen in the lower scores across several brands. The confusion matrix shows fewer correct predictions than in the 32% model, particularly for brands previously performing well, like BMW and Ferrari. This outcome suggests that integrating activation functions directly within convolutional layers may provide more stable learning.</p>
            <br><br>

            <h3>Summary Table of Model Runs and Results</h3>

            <table>
                <thead>
                    <tr>
                        <th>Evaluation</th>
                        <th>Model Changes</th>
                        <th>Test Accuracy</th>
                        <th>Precision</th>
                        <th>Recall</th>
                        <th>F1 Score</th>
                        <th>Observations</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Initial (model_916520)<br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/results/model_916520/classification_report_20241107_120051.txt" target="_blank">Classification Report</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/results/model_916520/confusion_matrix_20241107_120051.png" target="_blank">Confusion Matrix Heat Map</a>
                        </td>
                        <td>196 classes, no data augmentation</td>
                        <td>1%</td>
                        <td>0.00</td>
                        <td>0.00</td>
                        <td>0.00</td>
                        <td>Severe underfitting with random-like predictions; high computational burden from 1x1 convolution bottleneck</td>
                    </tr>
                    <tr>
                        <td>Second (model_916991)<br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/results/model_condensedclasssize_916991/classification_report_20241107_164005.txt" target="_blank">Classification Report</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/results/model_condensedclasssize_916991/confusion_matrix_20241107_164005.png" target="_blank">Confusion Matrix Heat Map</a>
                        </td>
                        <td>Reduced to 48 classes, 10 epochs, 10 steps/epoch</td>
                        <td>13%</td>
                        <td>0.11</td>
                        <td>0.13</td>
                        <td>0.07</td>
                        <td>Improved ability to distinguish brands; modest improvement for certain brands like Aston Martin and Ferrari; some correct predictions appeared</td>
                    </tr>
                    <tr>
                        <td>Third (model_917357)<br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/results/model_917357/classification_report_20241107_194802.txt" target="_blank">Classification Report</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/results/model_917357/confusion_matrix_20241107_194802.png" target="_blank">Confusion Matrix Heat Map</a>
                        </td>
                        <td>Added data augmentation</td>
                        <td>17%</td>
                        <td>0.14</td>
                        <td>0.17</td>
                        <td>0.13</td>
                        <td>Better generalization across varied lighting and contrast; increased performance for Audi, BMW, and Chrysler; improved diagonal clustering</td>
                    </tr>
                    <tr>
                        <td>Fourth (model_917372)<br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/results/model_32accuracy_917372/classification_report_20241107_205928.txt" target="_blank">Classification Report</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/results/model_32accuracy_917372/confusion_matrix_20241107_205928.png" target="_blank">Confusion Matrix Heat Map</a>
                        </td>
                        <td>30 epochs full steps</td>
                        <td>32%</td>
                        <td>0.36</td>
                        <td>0.32</td>
                        <td>0.29</td>
                        <td>Significant performance gain; better feature extraction for major brands; less-represented brands still underperformed</td>
                    </tr>
                    <tr>
                        <td>Fifth (model_917799)<br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/results/model_917799/classification_report_20241108_010740.txt" target="_blank">Classification Report</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/results/model_917799/confusion_matrix_20241108_010740.png" target="_blank">Confusion Matrix Heat Map</a>
                        </td>
                        <td>50 epochs full steps, observed overfitting</td>
                        <td>38%</td>
                        <td>0.47</td>
                        <td>0.38</td>
                        <td>0.37</td>
                        <td>Highest accuracy but clear overfitting with 70% train accuracy; frequent brands well-identified, less common brands poorly predicted</td>
                    </tr>
                    <tr>
                        <td>Sixth (model_926034)<br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/results/model_926034/classification_report_20241111_144402.txt" target="_blank">Classification Report</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/results/model_926034/confusion_matrix_20241111_144402.png" target="_blank">Confusion Matrix Heat Map</a>
                        </td>
                        <td>Extra activation layer after batch norm</td>
                        <td>24%</td>
                        <td>0.24</td>
                        <td>0.24</td>
                        <td>0.20</td>
                        <td>Performance declined with extra activation; reduced accuracy for most brands; activation within convolution layers preferable for stability</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <section id="reference">
            <h2>References</h2>
            <table class="reference-table">
                <tbody>
                    <tr>
                        <td>[1] S.S. Sarikan, A.M. Obayoglu, and O. Zilci, “Automated Vehicle Classification with Image Processing and Computational Intelligence,” Procedia Computer Science, vol. 114, pp. 515-522, 2017, doi: https://doi.org/10.1016/j.procs.2017.09.022.  </td>
                    </tr>
                    <tr>
                        <td>[2] W. Maungmai and C. Nuthong, "Vehicle Classification with Deep Learning,"2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS), Singapore, 2019, pp. 294-298, doi: 10.1109/CCOMS.2019.8821689.
                        </td>
                    </tr>
                    <tr>
                        <td>[3] Liang L, Ma H, Zhao L, Xie X, Hua C, Zhang M,and  Zhang Y, “Vehicle Detection Algorithms for Autonomous Driving: A Review”, Sensors (Basel). Vol 10, May, pp. 13-24, 2024, doi: 10.3390/s24103088.
                        </td>
                    </tr>
                    <tr>
                        <td>[4] M. Patel, “The Complete Guide to Image Preprocessing Techniques in Python,” Medium, Oct. 23, 2023. https://medium.com/@maahip1304/the-complete-guide-to-image-preprocessing-techniques-in-python-dca30804550c
                        </td>
                    </tr>
                    <tr>
                        <td> [5] “11.8. Transformers for Vision — Dive into Deep Learning 1.0.3 documentation,” d2l.ai. https://d2l.ai/chapter_attention-mechanisms-and-transformers/vision-transformer.html
                        </td>
                    </tr>
                    <tr>
                        <td> [6] A. A. M. Omer, “Image Classification Based on Vision Transformer,” Journal of Computer and Communications, vol. 12, no. 4, pp. 49-59, Apr. 2024, doi: https://doi.org/10.4236/jcc.2024.124005.
                        </td>
                    </tr>
                </tbody>
            </table>
        </section>

        <section id="contribution">
            <h2>Midterm Contributions</h2>
            <table>
                <thead>
                    <tr>
                        <th>Name</th>
                        <th>Midterm Contributions</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Madeline Liu Hou</td>
                        <td>Introduction section</td>
                    </tr>
                    <tr>
                        <td>Sophia Isabel Marples Rodriguez</td>
                        <td>Problem Definition section</td>
                    </tr>
                    <tr>
                        <td>Jiya Varma</td>
                        <td>Methods section, PowerPoint Slides</td>
                    </tr>
                    <tr>
                        <td>Nicole Hernandez Canales</td>
                        <td>Results and Discussion section and <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/resnet_exp.py" target="_blank">evaluate model and display results portion</a></td>
                    </tr>
                    <tr>
                        <td>Mengzhu Ou</td>
                        <td>Data Cleaning</td>
                    </tr>
                </tbody>
            </table>
        </section>
    </main>
</body>
</html>
