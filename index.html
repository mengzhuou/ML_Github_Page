<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vehicle Detection and Classification Final Report </title>
    <link rel="stylesheet" href="index.css">
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Vehicle Detection and Classification Proposal</h1>
            <h3>Jiya Varma, Madeline Liu Hou, Mengzhu Ou, Nicole Hernandez Canales, Sophia Isabel Marples Rodriguez</h3>
            <a href="https://github.com/mengzhuou/CS4641_CarClassification" class="btn" target="_blank">View on GitHub</a>
        </div>
    </header>

    <main>
        <section id="introduction">
            <h2>Introduction</h2>
            <p>Vehicle detection and classification are crucial for traffic control, management, and surveillance, but manual monitoring of traffic footage is inefficient, considering the volume of vehicles in high-traffic areas. Automated vehicle classification systems can address this problem by using machine learning algorithms to detect and categorize vehicles in real-time.</p><br/>
            <h3>Literature Review</h3>
            <p>
                Automated vehicle classification systems remain difficult to implement, considering issues such as the computational constraints of video processing, the effect of poor weather and environmental conditions, and occlusion [1]. Researchers have focused on improving vehicle detection using machine learning classifiers and deep learning methods, such as CNN-based methods, YOLO, and Vision Transformer (ViT) techniques [1], [2], [3].
            </p><br/>

            <h3>Dataset Description</h3>
            <p>We plan to use the Stanford Cars dataset for training our models. The dataset contains 16,185 images across 196 different classes of cars, with annotations for each class describing the make, model, and year of the car. </p><br/>
            <li><a href="https://www.kaggle.com/datasets/jessicali9530/stanford-cars-dataset" target="_blank">Dataset Link</a></li>
            </ul>
        </section>

        <section id="problem-definition">
            <h2>Problem Definition</h2>
            <p>In our project, we seek to perform multi-class car classification on car images from various brands such as BMW, Acura, Honda, etc. As previously covered, the use cases of car classification ranges from law enforcement to traffic control. Our project seeks to improve upon existing methods.</p>
        </section>
        
        <section id="gantt">
            <h2>Gantt Chart</h2>
            <a href="https://gtvault-my.sharepoint.com/:x:/r/personal/srodriguez67_gatech_edu/_layouts/15/Doc.aspx?sourcedoc=%7B83F8A18E-E3EF-4F5F-86D2-9EF9D988573C%7D&file=GanttChart.xlsx&fromShare=true&action=default&mobileredirect=true" target="_blank">Gantt Chart Link</a>
        </section>

        <section id="methods">
            <h2>Implemented Methods</h2>

            <p>This section describes the implemented methods for analyzing and classifying the condensed Stanford Cars dataset. Three approaches were explored: a convolutional neural network (CNN) based on a Residual Neural Network architecture, Visual Transformer (ViT) model, and various clustering methods implemented using Gaussian Mixture Models (GMM) and other algorithms.</p>
            <br>
            <p>We will resize all images to ensure consistent input dimensions, as neural networks require uniform image sizes for layers like convolution. Data augmentation (e.g., rotation, flipping, noise injection and reduction, cropping) will be applied to generate additional images, increasing the dataset size and preventing overfitting [4]. Pixel normalization will standardize lighting conditions and ensure consistent image scales.</p>
            <br>
            <p>The Vision Transformer (ViT) requires “patches” from the input image, and thus a patch-creation pre-processing step will be required [5]. We plan to train 2 supervised models, Convolution neural networks (CNN) and Vision transformer (ViT), and one unsupervised model, Gaussian Mixture model (GMM), for car classification.</p>
            <br>
            <ul>
                <li>CNNs are effective in image classification due to hierarchical feature detection (e.g., edges, wheels, chassis detection) and translation invariance (e.g., different angles/location of car in images) when trained on a strong dataset [7].</li>
                <li>ViT, which sequentially processes image patches using self-attention, has shown comparable performance to CNNs when trained on large datasets [6].</li>
                <li>GMM will reduce our dataset's class size of car makes/models to fewer clusters of chassis shapes (e.g., sedan, coupe, SUV), creating a more manageable dataset for training.</li>
            </ul>
            <br>

            <h3>CNN - Residual Neural Network</h3>
            <p>For our first model implementation, we decided to create a Residual Network Model, or ResNet, based on Microsoft Research's 2015 publication. The core concept of the ResNet model is the residual block, which creates a direct connection from some input to a deeper convolution layer's output, essentially "skipping" computations in between. This is useful in preventing vanishing or exploding gradients that often occur in deeper architectures due to high frequency of multiplications. The skip connections ensure that the gradients are kept secure from becoming too small or large, and allow for an easier flow path during backpropagation so that the network can more effectively adjust the weights. This is effective for producing a generalizable model as it can learn patterns across deeper layers without getting lost [8].</p>
            <br>
            <p>Our residual block contains 2x convolution (with rectified linear unit, or ReLu activation) + batch norm blocks such that the input tensor is added to the result of the second convolution output, and then finally passes through a ReLu activation before being returned.</p>
            <br>
            <p>The current architecture of our ResNet Model is as follows:
            [input tensor -> data augmentation layers -> initial convolution -> batch norm -> activation -> residual block 1 -> residual block 2 -> residual block 3 -> global average pooling -> flatten -> dense layer (with softmax)] [10],[11],[12]</p>
            <br>
            <p>We increase the filter size between each residual block to capture more complex features of our car image dataset, (theoretically) such as chassis shape or car brand logos [9]. To offset the computational cost of increased number of feature maps and maintain uniform dimensions, we employ a projection or bottleneck convolution layer with a 1x1 kernel size that ensures that the number of channels/depth of the input matches the # of channels of the residual block's second convolution's output [15].</p>
            <br>
            <p>We also employ Sparse Categorical cross entropy as our loss function as it allows direct indexing of class labels rather than requiring one-hot encoding, which is helpful for our pipeline as we have a large class size of 48 [14]. Additionally, we opted to use 'adam' (adaptive moment estimator) as our optimizer as it allows more flexibility in adjusting learning rates based on how large/small the gradients are. We have found that 'adam' is a good first choice due to its faster convergence speed and applicability to several problems without extensive need for hyperparameter tuning [13]. However, we plan to run several hyperparameter tuning experiments with various optimizers, learning rates, momentum decay, etc in order to improve our model performance.</p>
            <br><br>

            <h3>GMM - Gaussian Mixture Models</h3>
    
            <p>This section explores four distinct approaches undertaken to classify and understand the Stanford Cars dataset using a combination of supervised and unsupervised machine learning methods. The first approach compares the clustering capabilities of Gaussian Mixture Models (GMM) and K-Means, utilizing silhouette scores and other metrics for evaluation. The second approach extends the unsupervised pipeline by introducing DBSCAN and Spectral Clustering to address non-spherical and arbitrarily shaped clusters. The third approach integrates a hybrid K-Means + GMM pipeline to refine clustering by leveraging the strengths of both methods. Finally, the fourth approach combines supervised models—Random Forest and Support Vector Machines (SVM)—with the unsupervised methods, enabling a direct comparison of supervised and unsupervised learning paradigms. Each approach is presented with details on pipeline structure, design choices, and the reasoning behind key decisions.</p>
            <br>

            <h4>Approach 1: GMM vs K-Means - model_997376_100-iters_150-pca-components</h4>
        
            <p>This approach focuses on implementing Gaussian Mixture Models (GMM) and K-Means to cluster the dataset into groups that share common features, such as chassis shape or overall dimensions. The goal was to explore the efficacy of GMM in providing cluster structures while leveraging silhouette scores and other metrics for evaluation. GMM was chosen for its ability to model data with mixed Gaussian distributions, a property suitable for complex datasets like cars [16].</p>
            <br>
        
            <h4>Pipeline Structure and Flow</h4>
            <p>
                Each pipeline consists of four main components:
                Data Loading, Clustering, Metrics Evaluation, and Visualization. 
                The <em>data_loader.py</em> preprocessed the dataset by normalizing image data and applying PCA with 150 components, reducing computational complexity and noise. 
                The <em>gmm_pipeline.py</em> implemented clustering using Gaussian Mixture Models (GMM) and K-Means, iterating over different cluster sizes (<em>k</em>) and covariance types.
                Metrics evaluation included accuracy, precision, recall, F1 score, Fowlkes-Mallows score, and silhouette score. The results and visualizations (e.g., t-SNE and confusion matrices) were stored for qualitative and quantitative analysis.
            </p>
            <br>
        
            <h4>Key Design Choices and Reasoning</h4>
            <p>
                Key decisions included using PCA for dimensionality reduction, which balanced retaining dataset variance while reducing complexity, and employing multiple covariance types in GMM (<em>full</em>, <em>diag</em>), allowing flexibility in cluster shapes. 
                The Hungarian Algorithm was used to map predicted clusters to ground truth labels for meaningful metric computation [17]. 
                The inclusion of silhouette scores provided insights into cluster cohesion and separation.
            </p>
            <br><br>
        
            <h4>Approach 2: DBSCAN and Spectral Clustering - model_998281_100-iters_50-pca-components</h4>
        
            <p>In this approach, additional clustering algorithms were introduced, including DBSCAN and Spectral Clustering, alongside GMM and K-Means. DBSCAN was selected for its ability to handle arbitrary cluster shapes and detect outliers, while Spectral Clustering was included for its ability to cluster non-linearly separable data. This approach further sought to refine the dimensionality reduction step with PCA, reducing the components to 50 for improved efficiency [18].</p>
            <br>
        
            <h4>Pipeline Structure and Flow</h4>
            <p>
                This iteration of the pipeline extended clustering capabilities by integrating DBSCAN and Spectral Clustering in addition to GMM and K-Means. The <em>data_loader.py</em> script maintained the preprocessing steps but reduced PCA components to 50 to improve computational efficiency. 
                The <em>gmm_pipeline.py</em> explored various clustering parameters, such as DBSCAN’s <em>eps</em> and <em>min_samples</em>, and GMM’s covariance types (<em>full</em>, <em>tied</em>, <em>diag</em>, and <em>spherical</em>).
                Metrics evaluation and visualization components remained consistent, allowing direct comparisons between clustering methods.
            </p>
            <br>
        
            <h4>Key Design Choices and Reasoning</h4>
            <p>
                The inclusion of multiple clustering algorithms aimed to address the limitations of GMM and K-Means in handling overlapping or non-spherical clusters. DBSCAN was particularly chosen for its ability to detect arbitrary cluster shapes and identify outliers, with parameters <em>eps</em> and <em>min_samples</em> dynamically adjusted for experimentation. 
                PCA was reduced to 50 components to further streamline computations, balancing variance retention and dimensionality reduction. Visualizations were leveraged to qualitatively evaluate the separability of clusters across algorithms.
            </p>
            <br><br>

            <h4>Approach 3: Hybrid K-Means + GMM - model_998850_100-iters_50-pca-components</h4>
        
            <p>This approach combines the strengths of K-Means and Gaussian Mixture Models (GMM) into a hybrid pipeline. K-Means is employed for pre-clustering, initializing centroids that are subsequently refined by GMM. This two-stage approach is designed to mitigate initialization challenges in GMM and improve overall clustering performance. The pipeline leverages PCA for dimensionality reduction, allowing efficient computation while maintaining key data features. This hybrid method addresses the limitations of standalone clustering algorithms, particularly in datasets with overlapping clusters or non-spherical distributions [19].</p>
            <br>
            
            <h4>Pipeline Structure and Flow</h4>
            <p>
            The pipeline begins with the preprocessing step, where PCA reduces the dataset to 50 principal components. This dimensionality reduction preserves the dataset's variance while reducing computational complexity. Following PCA, K-Means is utilized as a pre-clustering method to identify initial centroids. This step ensures a stable starting point for the subsequent GMM refinement by addressing the initialization sensitivity found in GMM. The centroids derived from K-Means are used as the initialization points (`means_init`) for GMM, allowing the algorithm to converge faster and model more complex cluster shapes. The entire pipeline is automated to store results and visualizations in structured directories, facilitating an efficient comparison across different configurations.
            </p>
            <br>
                    
            <h4>Key Design Choices and Reasoning</h4>
            <p>
            K-Means is computationally efficient and provides a deterministic clustering result, which is really good as an initialization method for GMM. GMM, in turn, refines these clusters by using its probabilistic framework. Dimensionality reduction through PCA remained at 50 components to ensure that the computational load remained manageable while retaining significant variance in the dataset. Multiple covariance types—<em>full</em>, <em>diag</em>, <em>tied</em>, and <em>spherical</em>—were explored to allow the model to adapt to various cluster shapes and data distributions [20]. The iterative refinement enabled by this hybrid approach not only improves the quality of the clusters but also ensures that the initialization step from K-Means mitigates GMM's sensitivity to random starts. Metrics and visualization components were integral to validating the pipeline's effectiveness, ensuring that results were both quantitatively robust and qualitatively interpretable [21].
            </p>
            <br><br>

            <h4>Approach 4: Random Forest & SVM - model_999191_100-iters_100-pca-components</h4>

            <p>This approach incorporates supervised learning methods (Random Forest and Support Vector Machines) alongside unsupervised clustering techniques (K-Means and GMM). By evaluating both supervised and unsupervised approaches on the same dataset, the approach explores their comparative strengths and weaknesses. The supervised models aim to maximize predictive accuracy using labeled data, while the unsupervised methods explore inherent cluster structures within the dataset. The pipeline emphasizes a comprehensive evaluation of these models under a consistent preprocessing framework.</p>
            <br>
            
            <h4>Pipeline Structure and Flow</h4>
            <p>
            The pipeline begins with data preprocessing using PCA to reduce dimensionality to 100 components, which balances computational efficiency with data variance preservation. For supervised learning, the preprocessed dataset is split into training and testing subsets. Random Forest and SVM models are then trained on the labeled training data and evaluated using the testing set. In parallel, the unsupervised methods—K-Means and GMM—are applied to the preprocessed data, exploring various configurations of cluster sizes (<em>k</em>) and covariance types for GMM. The clustering results are evaluated using metrics such as silhouette scores, Fowlkes-Mallows scores, and visualizations like t-SNE plots and confusion matrices.
            </p>
            <br>
            
            <h4>Key Design Choices and Reasoning</h4>
            <p>
            Random Forest was chosen for its robustness to overfitting and ability to handle large datasets with minimal parameter tuning, while SVM provided a linear baseline to compare against the more complex clustering results. PCA was extended to 100 components in this approach to ensure that sufficient data variance was preserved for the supervised models, which typically rely on higher-dimensional representations. We maintained the integration of hybrid K-Means + GMM methods to combine the computational simplicity of K-Means with the flexibility of GMM to model overlapping and non-spherical clusters.
            </p>
        </section>

        <section id="methods">
            <h2>Data Cleaning</h2>

            <p>To ensure the quality and consistency of our dataset, we implemented several data cleaning steps across both the training and test datasets:</p>
            <br>
            <ul>
                <li><strong>Folder Filtering</strong>: Folders containing 30 or fewer images were removed. This threshold was set to maintain a balanced distribution of images per category.</li>
                <li><strong>Image Resizing with Aspect Ratio Preservation</strong>: All images were resized to a consistent target size of 224 x 224 pixels. To avoid distortion, aspect ratios were preserved, and padding was added where necessary. This ensured that all images met the required input dimensions for the neural network without compromising image quality.</li>
                <li><strong>Format Standardization</strong>: All images were converted to the JPEG format to establish consistent compatibility with the neural network and ensure consistency across the dataset.</li>
            </ul>
        </section>

        <section id="methods">
            <h2>Data Pre-Processing/Loading</h2>
    
            <p>The original Stanford Cars dataset evenly split images between test and train sets but did not include a validation set. To address this, we decided to adjust the distribution to a 80-10-10 split—80% for training, 10% for validation, and 10% for testing, also shifting the majority of images to our training set. We combined each car’s test and train images into a unified set. From this merged set, we randomly divided the images into the new 80-10-10 distribution.</p>
            <br>
            <p>To improve our model’s accuracy, we implemented the following data preprocessing steps:</p><br>
            <ul>
                <li><strong>Batching:</strong> Our train, test, and validation datasets were divided in smaller batches of 32 images each, reducing memory usage and allowing faster training and faster convergence of our model [22].</li>
                <li><strong>Normalization of pixels:</strong> The pixel values of each image were normalized by dividing each pixel value by 255, resulting in values within the range [0, 1]. This helped maintain stable gradients and improved computation speed [23].</li>
                <li><strong>Data prefetching:</strong> Prefetching allowed the model to dynamically load the next batches based on current resources, minimizing wait time between batches. This allowed for faster training and optimized resource usage [24].</li>
                <li><strong>Data augmentation:</strong> The training dataset was synthetically increased with data augmentation techniques, including random horizontal flips, and slight rotations and slight zooms to reduce overfitting [25].</li>
            </ul>
        </section>

        <section id="results-discussion">
            <h2>Results and Discussion</h2>
            
            <p>The ResNet model implemented here is inspired by Microsoft's 2015 ResNet architecture, leveraging residual blocks to enable deep learning without gradient vanishing or explosion issues. Each residual block in the model comprises two convolutional layers with batch normalization, connected by skip connections. These skip connections help preserve gradients across layers, allowing for more stable and effective training even in deep networks. The model processes input data through an initial convolution, followed by three residual blocks that increase the number of filters to capture complex features. A bottleneck 1x1 convolution aligns the dimensions between residual blocks to keep the feature map size consistent, which is essential for efficient learning without inflating computational costs. The model concludes with a global average pooling layer, flattening, and a dense softmax layer for classification. The use of sparse categorical cross-entropy as the loss function helps simplify label handling, and the Adam optimizer accelerates convergence with minimal hyperparameter adjustments.</p>
            <br>
            In our best result <b>Seventh Evaluation</b>, we observed the following from the <b>Loss Plot</b> and the <b>Accuracy Plot</b>:
            <br><br>
            <p>
                The loss plot shows that the training loss steadily decreases, indicating that the model is effectively minimizing the loss on the training data. However, the validation loss initially decreases but exhibits fluctuations and a dramatic spike around epoch 40. This suggests potential overfitting, instability in the learning process, or a learning rate issue that caused the model to diverge temporarily on the validation data. 
            </p>
            <br>
            <p>
                The accuracy plot reveals a growing gap between the training and validation accuracy. The training accuracy improves consistently and approaches 0.9, whereas the validation accuracy plateaus around 0.45 with fluctuations. This indicates overfitting, where the model is memorizing the training data but struggles to generalize to the validation set. The lack of improvement in validation accuracy suggests either insufficient model capacity, suboptimal hyperparameters, or inadequate regularization.
            </p>
            <br>
            <h3>Initial Evaluation (0% Accuracy)</h3>
            <p>The first run, with 196 classes and no data augmentation, yielded 0% test accuracy (initally 1% at epoch 1, but decreased with each epoch) and no meaningful precision, recall, or F1 scores across classes. This was largely due to the high class count, which overwhelmed the model, and the computational burden from the 1x1 bottleneck convolution layer, which introduced inefficiencies. The confusion matrix revealed nearly random predictions, indicating severe underfitting. At this stage, the model lacked the ability to generalize effectively, likely due to insufficient gradient flow and difficulty learning distinctive features for each class.</p>
            <br>

            <h3>Second Evaluation (13% Accuracy, Reduced Classes)</h3>
            <p>Reducing the class count from 196 to 48 improved the model's ability to distinguish between brands, resulting in a 13% accuracy increase. This reduction made the task more manageable, allowing the model to start learning specific brand features, though still at a limited level. Precision and recall scores showed modest improvement, particularly for brands like Aston Martin, Ferrari, and Chevrolet. The confusion matrix demonstrated an increase in correctly predicted classes but still displayed significant misclassifications, suggesting further optimization was needed.</p>
            <br>

            <h3>Third Evaluation (17% Accuracy, Added Data Augmentation)</h3>
            <p>Adding data augmentation layers led to a 17% test accuracy, as augmentation introduced variability in the training set, allowing the model to generalize better across different lighting, contrast, and orientation conditions. Brands like Audi, BMW, Chrysler, and Ferrari saw further improvement in precision, recall, and F1 scores, indicating that the model was increasingly capable of recognizing brand-specific features. The confusion matrix showed increased clustering along the diagonal, especially for brands with a substantial number of samples, though performance on less-represented brands remained low.</p>
            <br>

            <h3>Fourth Evaluation (32% Accuracy, 30 Epochs)</h3>
            <p>The model reached 32% accuracy after training for 30 epochs, allowing it to better internalize features across brands. This run saw notable improvements in both precision and recall for brands like Acura, Audi, BMW, Ferrari, and HUMMER. The longer training time allowed the model to recognize distinctive patterns, but brands with limited data still had poor performance, as reflected in the confusion matrix. This indicates a need for techniques to address class imbalance, such as weighted loss functions, to further improve generalization.</p>
            <br>

            <h3>Fifth Evaluation (38% Accuracy, 50 Epochs, Overfitting Observed)</h3>
            <p>With 50 epochs, the model achieved a 38% test accuracy and an F1 score of 0.37. However, training accuracy reached 70%, suggesting overfitting as the validation accuracy stagnated at 36%. This was confirmed in the confusion matrix, where frequently seen brands showed strong performance while rarer brands remained problematic. The model learned specific details rather than general patterns, which compromised its ability to generalize. Regularization methods, such as dropout or weight decay, may help prevent this overfitting in future runs.</p>
            <br>

            <h3>Sixth Evaluation (24% Accuracy, Extra Activation Layer)</h3>
            <p>Adding a separate activation layer on top of batch normalization within the residual blocks reduced test accuracy to 24% and F1 score to 0.2, indicating degraded model performance. The addition of an extra activation layer disrupted the learning dynamics within residual blocks, as seen in the lower scores across several brands. The confusion matrix shows fewer correct predictions than in the 32% model, particularly for brands previously performing well, like BMW and Ferrari. This outcome suggests that integrating activation functions directly within convolutional layers may provide more stable learning.</p>
            <br>

            <h3>Seventh Evaluation (43% Accuracy, 60 Epochs, Overfitting Observed)</h3>
            <p>The model achieved 43% accuracy on the test set, with an F1 score of 0.41. While brands like HUMMER and Acura performed relatively well (F1 scores above 60%), rarer brands like Cadillac and Porsche had near-zero performance due to class imbalance. Overfitting was evident, with training accuracy reaching 91%, but validation accuracy lagging at 44.4%. </p>
            <br>
            
            <h3>Eighth Evaluation (15% Accuracy, 62 Epochs, Hyperparameter Tuning)</h3>

            <p>
                The model achieved 15% accuracy on the test set, with an F1 score of 0.13. While hyperparameter tuning was applied with learning rate of 1e-3, the model's performance was relatively poor due to limited generalization capabilities. The large gap between training and testing accuracy suggests that further tuning or architectural changes are needed to improve the results.
            </p>
            <br>

            <h3>Ninth Evaluation (27% Accuracy, 62 Epochs, Improved Hyperparameter Tuning)</h3>
            <p>
                The model achieved 27% accuracy on the test set, with an F1 score of 0.22. This marks a notable improvement over the eighth evaluation with learning rate of 1e-4, indicating that adjustments in hyperparameter tuning, such as learning rate and batch size, helped the model generalize better. However, the performance still requires significant optimization to handle the complexity of the classification task effectively.
            </p>
            <br><br>
            
            <h3>Summary Table of Model Runs and Results</h3>
            
            <table>
                <thead>
                    <tr>
                        <th>Evaluation</th>
                        <th>Model Changes</th>
                        <th>Test Accuracy</th>
                        <th>Precision</th>
                        <th>Recall</th>
                        <th>F1 Score</th>
                        <th>Observations</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Initial (model_916520)<br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_916520/classification_report_20241107_120051.txt" target="_blank">Classification Report</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_916520/confusion_matrix_20241107_120051.png" target="_blank">Confusion Matrix Heat Map</a>
                        </td>
                        <td>196 classes, no data augmentation</td>
                        <td>1%</td>
                        <td>0.00</td>
                        <td>0.00</td>
                        <td>0.00</td>
                        <td>Severe underfitting with random-like predictions; high computational burden from 1x1 convolution bottleneck</td>
                    </tr>
                    <tr>
                        <td>Second (model_916991)<br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_condensedclasssize_916991/classification_report_20241107_164005.txt" target="_blank">Classification Report</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_condensedclasssize_916991/confusion_matrix_20241107_164005.png" target="_blank">Confusion Matrix Heat Map</a>
                        </td>
                        <td>Reduced to 48 classes, 10 epochs, 10 steps/epoch</td>
                        <td>13%</td>
                        <td>0.11</td>
                        <td>0.13</td>
                        <td>0.07</td>
                        <td>Improved ability to distinguish brands; modest improvement for certain brands like Aston Martin and Ferrari; some correct predictions appeared</td>
                    </tr>
                    <tr>
                        <td>Third (model_917357)<br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_917357/classification_report_20241107_194802.txt" target="_blank">Classification Report</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_917357/confusion_matrix_20241107_194802.png" target="_blank">Confusion Matrix Heat Map</a>
                        </td>
                        <td>Added data augmentation</td>
                        <td>17%</td>
                        <td>0.14</td>
                        <td>0.17</td>
                        <td>0.13</td>
                        <td>Better generalization across varied lighting and contrast; increased performance for Audi, BMW, and Chrysler; improved diagonal clustering</td>
                    </tr>
                    <tr>
                        <td>Fourth (model_917372)<br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_32accuracy_917372/classification_report_20241107_205928.txt" target="_blank">Classification Report</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_32accuracy_917372/confusion_matrix_20241107_205928.png" target="_blank">Confusion Matrix Heat Map</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_32accuracy_917372/accuracy_plot.png" target="_blank">Accuracy Plot</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_32accuracy_917372/loss_plot.png" target="_blank">Loss Plot</a>
                        </td>
                        <td>30 epochs full steps</td>
                        <td>32%</td>
                        <td>0.36</td>
                        <td>0.32</td>
                        <td>0.29</td>
                        <td>Significant performance gain; better feature extraction for major brands; less-represented brands still underperformed</td>
                    </tr>
                    <tr>
                        <td>Fifth (model_917799)<br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_917799/classification_report_20241108_010740.txt" target="_blank">Classification Report</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_917799/confusion_matrix_20241108_010740.png" target="_blank">Confusion Matrix Heat Map</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_917799/accuracy_plot.png" target="_blank">Accuracy Plot</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_917799/loss_plot.png" target="_blank">Loss Plot</a>
                        </td>
                        <td>50 epochs full steps, observed overfitting</td>
                        <td>38%</td>
                        <td>0.47</td>
                        <td>0.38</td>
                        <td>0.37</td>
                        <td>Highest accuracy but clear overfitting with 70% train accuracy; frequent brands well-identified, less common brands poorly predicted</td>
                    </tr>
                    <tr>
                        <td>Sixth (model_926034)<br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_926034/classification_report_20241111_144402.txt" target="_blank">Classification Report</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_926034/confusion_matrix_20241111_144402.png" target="_blank">Confusion Matrix Heat Map</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_926034/accuracy_plot.png" target="_blank">Accuracy Plot</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_926034/loss_plot.png" target="_blank">Loss Plot</a>
                        </td>
                        <td>Extra activation layer after batch norm</td>
                        <td>24%</td>
                        <td>0.24</td>
                        <td>0.24</td>
                        <td>0.20</td>
                        <td>Performance declined with extra activation; reduced accuracy for most brands; activation within convolution layers preferable for stability</td>
                    </tr>
                    <tr>
                        <td>Seventh (model_983557)<br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_43accuracy_983557/classification_report_20241126_044454.txt" target="_blank">Classification Report</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_43accuracy_983557/confusion_matrix_20241126_044454.png" target="_blank">Confusion Matrix Heat Map</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_43accuracy_983557/accuracy_plot.png" target="_blank">Accuracy Plot</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_43accuracy_983557/loss_plot.png" target="_blank">Loss Plot</a>
                        </td>
                        <td>60 epochs full steps, observed overfitting</td>
                        <td>43%</td>
                        <td>0.46</td>
                        <td>0.43</td>
                        <td>0.41</td>
                        <td>Advanced data augmentation techniques such as random contrast and brightness adjustments and random cropping were added, which improved the model's accuracy by 10%.</td>
                    </tr>
                    <tr>
                        <td>Eighth (model_988968)<br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_Hyperparameter_15accuracy_988968/classification_report_20241127_152357.txt" target="_blank">Classification Report</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_Hyperparameter_15accuracy_988968/confusion_matrix_20241127_152357.png" target="_blank">Confusion Matrix Heat Map</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_Hyperparameter_15accuracy_988968/accuracy_plot.png" target="_blank">Accuracy Plot</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_Hyperparameter_15accuracy_988968/loss_plot.png" target="_blank">Loss Plot</a>
                        </td>
                        <td>62 epochs full steps, initial hyperparameter tuning</td>
                        <td>15%</td>
                        <td>0.16</td>
                        <td>0.15</td>
                        <td>0.13</td>
                        <td>Initial hyperparameter tuning resulted in poor performance, highlighting the need for further optimization.</td>
                    </tr>
                    <tr>
                        <td>Ninth (model_989280)<br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_Hyperparameter_27accuracy_989280/classification_report_20241127_184625.txt" target="_blank">Classification Report</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_Hyperparameter_27accuracy_989280/confusion_matrix_20241127_184625.png" target="_blank">Confusion Matrix Heat Map</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_Hyperparameter_27accuracy_989280/accuracy_plot.png" target="_blank">Accuracy Plot</a>
                            <br><br>
                            <a href="https://github.com/mengzhuou/CS4641_CarClassification/blob/main/CNN/results/model_Hyperparameter_27accuracy_989280/loss_plot.png" target="_blank">Loss Plot</a>
                        </td>
                        <td>62 epochs full steps, improved hyperparameter tuning</td>
                        <td>27%</td>
                        <td>0.22</td>
                        <td>0.27</td>
                        <td>0.22</td>
                        <td>Further hyperparameter adjustments led to a significant improvement in accuracy and generalization, indicating potential for optimization.</td>
                    </tr>
                </tbody>
            </table>
        </section>



        <section id="results-discussion">
            <h2>Next Steps</h2>
            
            <h3>Enhance Data Augmentation</h4>
            <p>While basic augmentation is included, additional strategies could further diversify the training data and improve model robustness. Since we already have random rotations, cropping, random contrast and brightness, we could expand these augmentations by incorporating random hue and saturation adjustments or replace brightness/contrast adjustments with a full-color jittering implementation for more comprehensive augmentation.</p>
            <br>

            <h3>Refinement of Model Architecture</h4>
            <p>The ResNetModel with three residual blocks may not have sufficient depth or feature extraction capabilities to handle a complex multi-class classification problem like this. Adding more blocks or using a pretrained ResNet might improve results.</p>
        </section>

        <section id="reference">
            <h2>References</h2>
            <table class="reference-table">
                <tbody>
                    <tr>
                        <td>[1] S.S. Sarikan, A.M. Obayoglu, and O. Zilci, “Automated Vehicle Classification with Image Processing and Computational Intelligence,” Procedia Computer Science, vol. 114, pp. 515-522, 2017, doi: https://doi.org/10.1016/j.procs.2017.09.022.  </td>
                    </tr>
                    <tr>
                        <td>[2] W. Maungmai and C. Nuthong, "Vehicle Classification with Deep Learning,"2019 IEEE 4th International Conference on Computer and Communication Systems (ICCCS), Singapore, 2019, pp. 294-298, doi: 10.1109/CCOMS.2019.8821689.
                        </td>
                    </tr>
                    <tr>
                        <td>[3] Liang L, Ma H, Zhao L, Xie X, Hua C, Zhang M,and  Zhang Y, “Vehicle Detection Algorithms for Autonomous Driving: A Review”, Sensors (Basel). Vol 10, May, pp. 13-24, 2024, doi: 10.3390/s24103088.
                        </td>
                    </tr>
                    <tr>
                        <td>[4] M. Patel, “The Complete Guide to Image Preprocessing Techniques in Python,” Medium, Oct. 23, 2023. https://medium.com/@maahip1304/the-complete-guide-to-image-preprocessing-techniques-in-python-dca30804550c
                        </td>
                    </tr>
                    <tr>
                        <td> [5] “11.8. Transformers for Vision — Dive into Deep Learning 1.0.3 documentation,” d2l.ai. https://d2l.ai/chapter_attention-mechanisms-and-transformers/vision-transformer.html
                        </td>
                    </tr>
                    <tr>
                        <td> [6] A. A. M. Omer, “Image Classification Based on Vision Transformer,” Journal of Computer and Communications, vol. 12, no. 4, pp. 49-59, Apr. 2024, doi: https://doi.org/10.4236/jcc.2024.124005.
                        </td>
                    </tr>
                    <tr>
                        <td> [7] “What is a Convolution Neural Network?,” Hpe.com, 2023. https://www.hpe.com/us/en/what-is/convolutional-neural-network.html
                        </td>
                    </tr>
                    <tr>
                        <td>[8] K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual Learning for Image Recognition,” arXiv.org, Dec. 10, 2015. https://arxiv.org/abs/1512.03385</td>
                    </tr>
                    <tr>
                        <td>[9] “(PDF) The Impact of Filter Size and Number of Filters on Classification Accuracy in CNN,” www.researchgate.net. https://www.researchgate.net/publication/342999107_The_Impact_of_Filter_Size_and_Number_of_Filters_on_Classification_Accuracy_in_CNN</td>
                    </tr>
                    <tr>
                        <td>[10] https://medium.com/swlh/how-to-create-a-residual-network-in-tensorflow-and-keras-cd97f6c62557</td>
                    </tr>
                    <tr>
                        <td>[11] https://github.com/Prakadeeswaran05/Customising-your-models-with-TensorFlow-2-Coursera/blob/main/Week%204%20Programming%20Assignment-Residual%20Network.ipynb</td>
                    </tr>
                    <tr>
                        <td>[12] https://www.youtube.com/watch?v=Q1JCrG1bJ-A</td>
                    </tr>
                    <tr>
                        <td>[13] https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam</td>
                    </tr>
                    <tr>
                        <td>[14] https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy</td>
                    </tr>
                    <tr>
                        <td>[15] https://www.geeksforgeeks.org/what-is-a-projection-layer-in-the-context-of-neural-networks/</td>
                    </tr>
                    <tr>
                        <td>[16] C. Bishop, “Pattern Recognition and Machine Learning,” Springer, 2006, pp. 352–356.</td>
                    </tr>
                    <tr>
                        <td>[17] H. W. Kuhn, “The Hungarian Method for the Assignment Problem,” Naval Research Logistics Quarterly, vol. 2, no. 1–2, pp. 83–97, 1955, doi: 10.1002/nav.3800020109.</td>
                    </tr>
                    <tr>
                        <td>[18] M. Ester, H. Kriegel, J. Sander, and X. Xu, “A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise,” in Proc. Int. Conf. on Knowledge Discovery and Data Mining (KDD), 1996, pp. 226–231.</td>
                    </tr>
                    <tr>
                        <td>[19] P.S. Bradley and U.M. Fayyad, “Refining Initial Points for K-Means Clustering,” Proceedings of the Fifteenth International Conference on Machine Learning, San Francisco, CA, USA, pp. 91–99, 1998.</td>
                    </tr>
                    <tr>
                        <td>[20] J. MacQueen, “Some Methods for Classification and Analysis of Multivariate Observations,” Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, vol. 1, pp. 281–297, 1967.</td>
                    </tr>
                    <tr>
                        <td>[21] C.M. Bishop, “Pattern Recognition and Machine Learning,” Springer, 2006, pp. 423–457.</td>
                    </tr>
                    <tr>
                        <td>[22] “Batch processing: The key to making your neural networks sing,” Tooliqa, https://www.tooli.qa/insights/batch-processing-the-key-to-making-your-neural-networks-sing (accessed Nov. 11, 2024).</td>
                    </tr>
                    <tr>
                        <td>[23] P. Harsh, “Normalization in image preprocessing: Scaling pixel values by 1/255,” Medium, https://medium.com/@patelharsh7458/normalization-in-image-preprocessing-scaling-pixel-values-by-1-255-111b2fa496d4 (accessed Nov. 11, 2024).</td>
                    </tr>
                    <tr>
                        <td>[24] “Better performance with the tf.data API,” TensorFlow, https://www.tensorflow.org/guide/data_performance (accessed Nov. 11, 2024).</td>
                    </tr>
                    <tr>
                        <td>[25] “Data augmentation,” TensorFlow, https://www.tensorflow.org/tutorials/images/data_augmentation (accessed Nov. 11, 2024).</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <section id="contribution">
            <h2>Midterm Contributions</h2>
            <table>
                <thead>
                    <tr>
                        <th>Name</th>
                        <th>Midterm Contributions</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Madeline Liu Hou</td>
                        <td>Introduction and data-preprocessing/loading section, data split/merge and data augmentation </td>
                    </tr>
                    <tr>
                        <td>Sophia Isabel Marples Rodriguez</td>
                        <td>Problem Definition section</td>
                    </tr>
                    <tr>
                        <td>Jiya Varma</td>
                        <td>Methods section, PowerPoint Slides, ResNet model implementation and training </td>
                    </tr>
                    <tr>
                        <td>Nicole Hernandez Canales</td>
                        <td>Methods section (GMM part), all files under the GMM directory in the project Github</td>
                    </tr>
                    <tr>
                        <td>Mengzhu Ou</td>
                        <td>Data Augmentation Improvement, Accuracy Plot and Loss Plot generation</td>
                    </tr>
                </tbody>
            </table>
        </section>
    </main>
</body>
</html>
